---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a final year Ph.D student in the College of Information Sciences and Technology at [Penn State University](https://www.psu.edu/) - University Park. My advisor is [Dr. Suhang Wang](https://suhangwang.ist.psu.edu/). I obtained my Master of AI degree from Computer Science Department at [KU Leuven](https://www.kuleuven.be/english/). I received my Bachelor Degree from the [University of Science and Technology of China](https://www.ustc.edu.cn/). 

<p style="color: #d9534f; font-weight: bold">
    I will join the 
    <a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/information-hub/artificial-intelligence/" style="color: #d9534f; text-decoration: none;">
        AI Thrust at Hong Kong University of Science and Technology (Guangzhou)
    </a> 
    to build and direct Trust & Application AI Lab (TAI Lab). 
</p>


<div style="background-color: #f9d9a6; padding: 10px; border: 2px solid #e0a96d;">
    <p style="font-size: 15px; color: #d9534f; font-weight: bold; display: inline;">
        [Ph.D. student and Research Assistant Positions available]
    </p>
    <p style="font-size: 15px; color: black; font-weight: bold; display: inline;">
    I am seeking highly self-motivated Ph.D. students and Research Assistants to join my team starting in Fall 2024, Spring 2025, or Fall 2025. Candidates with solid backgrounds in data mining, machine learning, mathematics and other related fields are encouraged to apply. If interested, please email me your CV and transcript, kindly using the subject line "[Ph.D./RA Application - your name]."
    </p>
</div>





## Research Directions at <img src="../images/logo.svg" style="height: 2.5em; vertical-align: middle;">(Trust & Application AI Lab)

The overview of the research directions are listed following. More details can be referred in my [research statement](../files/ResearchStatement.pdf).
<div style="display: flex; justify-content: center;">
    <img src="..\images\overview.svg" alt="Fake Health News Dataset Repository" style="width: 90%" class="image">
</div>

<style>
/* Basic reset*/
* {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
}
.mini-post {
    background: #fafafa;
    border: solid 1px rgba(160, 160, 160, 0.3);
    margin: 0.5em 0.5em 0.5em 0.5em;
    padding: 1em 1em 1em 1em;
    width: 30%;
    font-size: 13px
}
/* Container for the whole page content */

/* Style for links */
.link {
    background-color: #eee;
    padding: 2px 5px;
    margin: 2px 0;
    border-radius: 5px;
    text-decoration: none;
    color: #333;
}

.column {
    align-items: left;
    justify-content: center;
    margin: 0.5em 0.5em 0.5em 0.5em;
    padding: 1em 1em 1em 1em;
    width: 30%; /* Adjust as needed */
    height: 100%;
}

</style>




<h3> Summary of Prior Works </h3>
<div style="border: 1px dashed #000000;">
    <div style="display: flex;">
    <article class="mini-post">
        <img src="..\images\fairness.png" alt="Fairness" style="width: 140px; height=50px;" class="image">
        <p> <b> Fair Graph Neural Network </b> (WSDM-21) 
        <a href="https://arxiv.org/pdf/2009.01454.pdf" class="link">Paper</a> 
        <a href="https://github.com/EnyanDai/FairGNN" class="link">Code</a> </p>
        <p> <b> Privacy Preserving FairGNN </b> (TKDE) 
        <a href="https://enyandai.github.io/files/FairGNN_journal.pdf" class="link">Paper</a>
        </p>
    </article>
    <article class="mini-post">
        <img src="..\images\privacy.png" alt="Privacy" style="width: 130px;" class="image">
        <br>
        <b> Sensitive Attribute Protection </b> (TKDE) 
        <a href="https://enyandai.github.io/files/FairGNN_journal.pdf" class="link">Paper</a>
        <br>
        <b> Membership Privacy Protection </b> (KDD-23) 
        <a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599248" class="link">Paper</a>
        <br>
        <b> Deep IP Protection </b> (Preprint) 
        <a href="https://arxiv.org/abs/2402.04435" class="link">Paper</a>
    </article>
    <article class="mini-post">
        <img src="..\images\robustness.png" alt="robustness" style="width: 160px;" class="image">
        <br>
        <b> Label Noise-Resistant GNN </b> (KDD-21) 
        <a href="https://arxiv.org/abs/2106.04714" class="link">Paper</a> 
        <a href="https://github.com/EnyanDai/NRGNN" class="link">Code</a>
        <br> 
        <b> Defend Structural Noise </b> (WSDM-22)
        <a href="https://arxiv.org/pdf/2201.00232.pdf" class="link">Paper</a>
        <a href="https://github.com/EnyanDai/RSGNN" class="link">Code</a> 
        <br>
        <b> Unnoticeable Graph Backdoor </b> (WWW-23) 
        <a href="https://arxiv.org/pdf/2303.01263.pdf" class="link">Paper</a>
        <a href="https://github.com/EnyanDai/UGBA" class="link">Code</a> 
    </article>
    </div>
    <div style="display: flex;">
    <div class="column">
        <h3> Trustworthy Graph Learning </h3>
    </div>
    <article class="mini-post">
        <img src="..\images\explainability.png" alt="Explainability" style="width: 160px;" class="image">
        <p> <b> Self-Explainable GNN </b> (CIKM-21)
        <a href="https://arxiv.org/pdf/2108.12055.pdf" class="link">Paper</a>
        <a href="https://github.com/EnyanDai/SEGNN" class="link">Code</a>
        </p>
    </article>
    <article class="mini-post">
        <b> A Comprehensive Survey of Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability.  </b>
        <a href="https://arxiv.org/pdf/2204.08570.pdf" class="link">Paper</a>
    </article>
    </div>
</div>
<!-- <img src="..\images\interaction.png" alt="Fake Health News Dataset Repository" style="height: 40px" class="image"> -->
<div style="display: flex; border: 1px dashed #000000;">
<div class="column">
    <h3> Graph-Augmented AI for Social Good </h3>
</div>
<article class="mini-post">
    <img src="..\images\Fakehealth.png" alt="Fake Health News Dataset Repository" style="width: 170px" class="image">
    <p> <b> Fake Health News Repository </b> with Social Network Context (ICWMS-20)  
    <a href="https://arxiv.org/pdf/2002.00837.pdf" class="link">Paper</a>
    <a href="https://zenodo.org/record/3606757" class="link">Dataset</a>
    </p>
</article>
<article class="mini-post">
    <img src="..\images\GANF.png" alt="Graph-Augmented Anomaly Detection on Power Grids" style="width: 170px" class="image">
    <p> <b> Graph-Augmented Anomaly Detection on Power Grids </b> (ICLR-22)
    <a href="https://openreview.net/pdf?id=45L_dgP48Vd" class="link">Paper</a>
    <a href="https://github.com/EnyanDai/GANF" class="link">Code</a>
    </p>
</article>
</div>



## Recent Blogs
* [[Video] Introduction about Unnoticeable Backdoor Attacks on Graph Neural Networks (WWW-2023)](https://enyandai.github.io/posts/2023/04/UGBA/)
* [[Video] Introduction about robust structural noise-resistant GNN (WWW-2022)](https://enyandai.github.io/posts/2023/04/trustworthy/)
* [A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability](https://enyandai.github.io/posts/2022/04/trustworthy/)
  
## Invited Talks
* 06/2023: "Towards Trustworthy Graph Neural Networks in Fairness, Robustness, and Privacy" at University of Science and Technology of China
* 08/2022: "Graph Structure Learning for Robustness" at Amazon
* 06/2022: "Fairness and Explainability in Graph Neural Networks" at DataFunSummit2022

## News 
* 05/2024：I will join the AI Thrust at Hong Kong University of Science and Technology (Guangzhou) this summer.
* 05/2024: [One paper entitled: Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective]() accepted by KDD-2024
* 09/2023：[One paper entitiled: "Certifiably Robust Graph Contrastive Learning"]() accepted by NeurIPS-2023
* 09/2023：[One paper entitled:"Learning Fair Models without Sensitive Attributes: A Generative Approach"]() accepted by Neurocomputing 
* 05/2023: [One paper entitled:"A Unified Framework of Graph Information Bottleneck for Robustness and Membership Privacy"](https://arxiv.org/abs/2306.08604) accepted by KDD-2023
* 04/2023: Serve as reviewer of KDD-2023 and ICML-2023.
* 03/2023: Very glad to receive the IST Ph.D. Student Award for Research Excellence
* 01/2023: [One paper entitled: "Unnoticeable Backdoor Attacks on Graph Neural Networks"](https://arxiv.org/pdf/2303.01263.pdf) has been accepted by WWW-2023
* 11/2022: [One paper entitled: "Label-Wise Graph Convolutional Network for Heterophilic Graphs"](https://arxiv.org/abs/2110.08128) has been accepted by LOG-2022 
* 08/2022: One paper has been accepted by ICDM-2022
* 07/2022: [One paper entitled: "Learning Fair Graph Neural Networks with Limited andPrivate Sensitive Attribute Information"](https://enyandai.github.io/files/FairGNN_journal.pdf) has been accepted by TKDE
* 07/2022: Update a **package of Robust GNN for Label Noises** [[code](https://github.com/EnyanDai/NRGNN)]
* 06/2022: Serve as a reviewer for NeurIPS-2022
* 06/2022: Serve as a PC memeber for ASONAM-2022
* 06/2022: Invited as a guest for Trustworthy Graph Learning Tutorial in DataFun
* 04/2022: Release [a survey entitled: "A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability"](https://arxiv.org/pdf/2204.08570.pdf)
* 03/2022: Serve as a PC memeber for KDD-2022
* 01/2022: [One paper entitled "Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series"](https://openreview.net/pdf?id=45L_dgP48Vd) is accepted as **Spotlight in ICLR-2022**
* 10/2021: Two papers are accepted by WSDM-2022
* 08/2021: One paper is accepted by CIKM-2021
* 06/2021: Serve as a PC memeber for ASONAM-2021 
* 05/2021: Two papers are accepted by KDD-2021
* 10/2020: One paper is accepted by WSDM-2021
